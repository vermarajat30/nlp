{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d0bf6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "685fdec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"E:\\courses\\natural lang processing\\data sets for coure 1\\fake_news_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34b0a6d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f762b77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29727852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4d947ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e484920",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df.shape\n",
    "x = df.drop(\"label\" , axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd1ab096",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"label\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e7ed5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preprocessing\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "corpus = []\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "for i in range(0, len(x)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', x['title'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [lem.lemmatize(word) for word in review if word not in (stopwords.words(\"english\"))]\n",
    "    review = \" \".join(review)\n",
    "    \n",
    "    corpus.append(review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b563ccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing one hot representation\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e54ff49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = 5000\n",
    "\n",
    "onehot_repr = [one_hot(word , vocab ) for word in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a10d331b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3145, 4526, 3022, 1405, 2285, 777, 3816, 3809, 2251, 3372]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_repr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a9aa664",
   "metadata": {},
   "outputs": [],
   "source": [
    "#padding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3136cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_max_len = 20\n",
    "\n",
    "embedding_doc = pad_sequences(onehot_repr , padding = \"pre\" , maxlen = sent_max_len )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b6aed27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0, 3145,\n",
       "       4526, 3022, 1405, 2285,  777, 3816, 3809, 2251, 3372])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44f7d673",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.layers import Embedding , Dense , LSTM\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b2d03a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 20, 50)            250000    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               60400     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 310,501\n",
      "Trainable params: 310,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#creating model\n",
    "\n",
    "feature_vector = 50\n",
    "\n",
    "sq = Sequential()\n",
    "sq.add(Embedding(vocab , feature_vector , input_length = sent_max_len ))\n",
    "sq.add(LSTM(100))\n",
    "sq.add(Dense(1 , activation = \"sigmoid\"))\n",
    "\n",
    "# added all the layers, now compiling this model\n",
    "\n",
    "sq.compile(loss = \"binary_crossentropy\", optimizer = 'adam' , metrics = [\"accuracy\"])\n",
    "\n",
    "sq.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93c68753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9742a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(embedding_doc)\n",
    "Y =np.array(y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a654eabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating train-test-split and training the model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, Y , test_size = 0.33 , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2de5453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18285, 20), (18285,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape , y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4905ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "192/192 [==============================] - 10s 33ms/step - loss: 0.3239 - accuracy: 0.8496 - val_loss: 0.1947 - val_accuracy: 0.9175\n",
      "Epoch 2/10\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.1358 - accuracy: 0.9463 - val_loss: 0.2137 - val_accuracy: 0.9180\n",
      "Epoch 3/10\n",
      "192/192 [==============================] - 7s 35ms/step - loss: 0.0920 - accuracy: 0.9660 - val_loss: 0.2234 - val_accuracy: 0.9109\n",
      "Epoch 4/10\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.0630 - accuracy: 0.9776 - val_loss: 0.2890 - val_accuracy: 0.9095\n",
      "Epoch 5/10\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.0384 - accuracy: 0.9869 - val_loss: 0.3604 - val_accuracy: 0.9102\n",
      "Epoch 6/10\n",
      "192/192 [==============================] - 6s 34ms/step - loss: 0.0230 - accuracy: 0.9941 - val_loss: 0.3985 - val_accuracy: 0.9114\n",
      "Epoch 7/10\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 0.0147 - accuracy: 0.9958 - val_loss: 0.4887 - val_accuracy: 0.9044\n",
      "Epoch 8/10\n",
      "192/192 [==============================] - 7s 35ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.4942 - val_accuracy: 0.9021\n",
      "Epoch 9/10\n",
      "192/192 [==============================] - 7s 35ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.5800 - val_accuracy: 0.9092\n",
      "Epoch 10/10\n",
      "192/192 [==============================] - 7s 35ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.6142 - val_accuracy: 0.9065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19bd29dcfc8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training\n",
    "\n",
    "sq.fit(xtrain , ytrain, validation_data = (xtest , ytest), epochs = 10 , batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "791bbf12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[3123,  268],\n",
       "        [ 296, 2348]], dtype=int64),\n",
       " 0.9065451532725767)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# performance metrics and accuracy\n",
    "\n",
    "pred = (sq.predict(xtest) > 0.5).astype(\"int32\")\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix , accuracy_score\n",
    "\n",
    "confusion_matrix(pred, ytest), accuracy_score(pred, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6514896",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
